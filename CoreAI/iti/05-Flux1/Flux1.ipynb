{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux1\n",
    "\n",
    "The CoreAI container is started using the instructions described in the shared `README.md` file which uses `podman` or `docker`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enhance the functionality of the CoreAI  environment, we need to install some libraries not pre-installed but required for this notebook. \n",
    "\n",
    "## Pre-requisites\n",
    "Open your terminal or command prompt within the Jupyter notebook. Navigate via `File -> New -> Terminal`.\n",
    "Type `bash` to access a shell compatible with the following commands.\n",
    "Navigate to the project directory where you want to set up the environment:\n",
    "\n",
    "```bash\n",
    "export PROJECT_NAME=\"Flux1\"\n",
    "export PIP_CACHE_DIR=`pwd`/.cache/pip\n",
    "mkdir -p $PIP_CACHE_DIR\n",
    "python -m venv --system-site-packages myvenv\n",
    "source myvenv/bin/activate\n",
    "pip install ipykernel\n",
    "python -m ipykernel install --user --name=${PROJECT_NAME}-myvenv --display-name=\"Python (${PROJECT_NAME}-myvenv)\"\n",
    "echo \"\"; echo \"Before continuing load the created Python kernel: Python (${PROJECT_NAME}-myvenv)\"\n",
    "```\n",
    "\n",
    "Load the Python kernel described above before running the cell below (it might take a few seconds for the kernel to appear in the list of kernels).\n",
    "\n",
    "\n",
    "## Install Required Libraries:\n",
    "\n",
    "Before running the following commands, load the `Python (myvenv)` kernel.\n",
    "\n",
    "Ensure you are in the directory where the Jupyter Notebook and the `myvenv` directory are located. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!. ./myvenv/bin/activate; pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `accelerate` to the PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pwd = os.getcwd()\n",
    "os.environ['PATH'] =  os.path.join(pwd, 'myvenv/bin') + os.pathsep + os.environ['PATH']\n",
    "\n",
    "! echo $PATH\n",
    "! which accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure `HF_HOME` is set BEFORE `transformers` is loaded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('HF_HOME', exist_ok=True)\n",
    "os.environ['HF_HOME'] = 'HF_HOME'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the `HF_TOKEN` is set before attempting to load the model (this is passed as an environment variable within the `start_CoreAI.sh` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment configuration file\n",
    "# This sets up the basic structure for API credentials\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "if 'HF_TOKEN' not in os.environ:\n",
    "    printf(\"No HF_TOKEN set, will not be able to download the model\")\n",
    "    exit(1)\n",
    "\n",
    "hf_token=os.environ['HF_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Flux1\n",
    "\n",
    "### Obtain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import FluxPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up some memory before testing\n",
    "import gc\n",
    "\n",
    "# check memory\n",
    "print(torch.cuda.memory_allocated())\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# check memory again\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-dev\")\n",
    "pipe.enable_sequential_cpu_offload()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image generation\n",
    "\n",
    "Modify the `prompt`, `seed` and `width` and `height` as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import Image, display\n",
    "\n",
    "prompts = [\n",
    "    \"An ocean reflection on starry night with the word JetStream in the sky with whales and dolpins in the ocean\",\n",
    "    \"An galaxy with the word OpenStack spelled with stars\",\n",
    "    \"A friendly robot with wheels on a mars landscape moving toward the setting sun with the word Exosphere rising from the horizon\",\n",
    "    \"The sentence \\\"Happy Birthday OpenStack and Scientific SIG\\\" on a marvelous tropical forest\"\n",
    "]\n",
    "\n",
    "width = 1360\n",
    "height = 768\n",
    "\n",
    "c = 1\n",
    "while c < 5:\n",
    "\n",
    "    d = 1\n",
    "    for prompt in prompts:\n",
    "        seed = random.randint(1, 999)\n",
    "    \n",
    "        image = pipe(\n",
    "            prompt,\n",
    "            guidance_scale=0.0,\n",
    "            num_inference_steps=4,\n",
    "            max_sequence_length=256,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            generator=torch.Generator(\"cpu\").manual_seed(seed)\n",
    "        ).images[0]\n",
    "        fname = f\"flux-schnell-{c}-{d}.png\"\n",
    "        image.save(fname)\n",
    "\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        display(Image(filename=fname))\n",
    "        d += 1\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Flux1-myvenv)",
   "language": "python",
   "name": "flux1-myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
